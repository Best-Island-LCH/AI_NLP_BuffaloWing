{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "8414477c",
      "metadata": {
        "id": "8414477c"
      },
      "source": [
        "# RLHF Evaluation Notebook\n",
        "\n",
        "This notebook evaluates a base model vs an RLHF model using:\n",
        "1) RM-based scoring\n",
        "2) GPT-based preference judging\n",
        "3) Style/structure metrics\n",
        "\n",
        "Outputs: a markdown report and raw CSV/JSON artifacts.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "b67014fb",
      "metadata": {
        "id": "b67014fb"
      },
      "outputs": [],
      "source": [
        "# Install dependencies (Colab)\n",
        "!pip -q install transformers accelerate sentencepiece openai tiktoken\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tk2SQMw1300K",
        "outputId": "01144dd4-87f6-4bc4-f8b0-0547c974b9a7"
      },
      "id": "Tk2SQMw1300K",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "1b1d8d4e",
      "metadata": {
        "id": "1b1d8d4e"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import math\n",
        "import re\n",
        "from glob import glob\n",
        "from collections import Counter\n",
        "from datetime import datetime\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "from peft import PeftModel\n",
        "\n",
        "# ---- Config ----\n",
        "DATA_ROOT = \"/content/drive/Mydrive/LikeLion/Ïã§Ï†Ñ ÌîÑÎ°úÏ†ùÌä∏ 2/train\"\n",
        "DATA_GLOB = \"**/RMlabel.json\"\n",
        "MAX_SAMPLES = 50\n",
        "SEED = 42\n",
        "\n",
        "BASE_MODEL_ID = \"kakaocorp/kanana-1.5-8b-instruct-2505\"\n",
        "RLHF_ADAPTER_ID = \"jinn33/kanana-1.5-8b-rlhf\"\n",
        "REWARD_ADAPTER_ID = \"jinn33/kanana-1.5-8b-rm\"\n",
        "\n",
        "GEN_KWARGS = dict(max_new_tokens=512, temperature=0.7, top_p=0.9, do_sample=True)\n",
        "\n",
        "RUN_GPT_EVAL = True\n",
        "OPENAI_MODEL = \"gpt-4o-mini\"\n",
        "ANSWER_KEY = \"a\"\n",
        "\n",
        "TIMESTAMP = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "REPORT_PATH = f\"/content/drive/MyDrive/LikeLion/Ïã§Ï†Ñ ÌîÑÎ°úÏ†ùÌä∏ 2/evaluation/rlhf_eval_report_{TIMESTAMP}.md\"\n",
        "ARTIFACT_DIR = f\"/content/drive/MyDrive/LikeLion/Ïã§Ï†Ñ ÌîÑÎ°úÏ†ùÌä∏ 2/evaluation/artifacts_{TIMESTAMP}\"\n",
        "GEN_DIR = os.path.join(ARTIFACT_DIR, \"generations\")\n",
        "EVAL_DIR = os.path.join(ARTIFACT_DIR, \"eval\")\n",
        "\n",
        "os.makedirs(GEN_DIR, exist_ok=True)\n",
        "os.makedirs(EVAL_DIR, exist_ok=True)\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "np.random.seed(SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "c4028e57",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "id": "c4028e57",
        "outputId": "52836a1b-6884-40a4-87d8-8f3a142adaec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "Loaded 100 questions\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                data_id                      question\n",
              "0  0827c2bf-592d-4048-8f95-3c5fe336c1d1  ÎèôÎ¨ºÏóê ÎåÄÌïú Ïù∏ÏãùÏùÑ ÎÜíÏù¥Í≥† ÍµêÏú°ÌïòÎäî Îç∞ Í¥ÄÏã¨ ÏûàÏñ¥?\n",
              "1  e14a45b5-9e2c-44a1-ba37-e1015116e665           Ïñ∏Î°†Ïù¥ ÏÇ¨ÌöåÏóê ÎØ∏ÏπòÎäî ÏòÅÌñ•ÏùÄ Ïñ¥Îïå?\n",
              "2  6a5d63bf-ca9e-46a9-8e5c-0d6c5ea7ce81          ÏùºÎ≥∏ Ìï≠Í≥µÍ∂å ÏòàÏïΩÌïòÎäî Î∞©Î≤ï ÏïåÎ†§ Ï§ò.\n",
              "3  c6c9ba7c-116d-4b07-8815-00e0826044ad                 ÎÖ∏ÎûòÎ•º Î∞∞ÏõåÎ≥∏ Ï†Å ÏûàÏñ¥?\n",
              "4  081afbe1-8324-4650-9fc2-e5987f37cd1e           ÌôàÌä∏Î†àÏù¥Îãù Ïö¥Îèô ÏòÅÏÉÅÏùÑ Ï∂îÏ≤úÌï¥ Ï§ò."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-caaf11c1-6447-4f2f-adbe-c57221402a56\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data_id</th>\n",
              "      <th>question</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0827c2bf-592d-4048-8f95-3c5fe336c1d1</td>\n",
              "      <td>ÎèôÎ¨ºÏóê ÎåÄÌïú Ïù∏ÏãùÏùÑ ÎÜíÏù¥Í≥† ÍµêÏú°ÌïòÎäî Îç∞ Í¥ÄÏã¨ ÏûàÏñ¥?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>e14a45b5-9e2c-44a1-ba37-e1015116e665</td>\n",
              "      <td>Ïñ∏Î°†Ïù¥ ÏÇ¨ÌöåÏóê ÎØ∏ÏπòÎäî ÏòÅÌñ•ÏùÄ Ïñ¥Îïå?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6a5d63bf-ca9e-46a9-8e5c-0d6c5ea7ce81</td>\n",
              "      <td>ÏùºÎ≥∏ Ìï≠Í≥µÍ∂å ÏòàÏïΩÌïòÎäî Î∞©Î≤ï ÏïåÎ†§ Ï§ò.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>c6c9ba7c-116d-4b07-8815-00e0826044ad</td>\n",
              "      <td>ÎÖ∏ÎûòÎ•º Î∞∞ÏõåÎ≥∏ Ï†Å ÏûàÏñ¥?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>081afbe1-8324-4650-9fc2-e5987f37cd1e</td>\n",
              "      <td>ÌôàÌä∏Î†àÏù¥Îãù Ïö¥Îèô ÏòÅÏÉÅÏùÑ Ï∂îÏ≤úÌï¥ Ï§ò.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-caaf11c1-6447-4f2f-adbe-c57221402a56')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-caaf11c1-6447-4f2f-adbe-c57221402a56 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-caaf11c1-6447-4f2f-adbe-c57221402a56');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 100,\n  \"fields\": [\n    {\n      \"column\": \"data_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 100,\n        \"samples\": [\n          \"050b2e5d-8248-4595-95c1-df455a15e6f0\",\n          \"07a5cf87-4193-4183-85b7-f62e38601a1d\",\n          \"42d4e3dc-89be-4f81-a392-837acdc1ac6b\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 100,\n        \"samples\": [\n          \"\\uc2dc\\uc98c\\ub9c8\\ub2e4\\uc758 \\uc778\\ubca4\\ud1a0\\ub9ac \\uad00\\ub9ac \\uc2dc\\uc2a4\\ud15c\\uc740 \\uc5b4\\ub5bb\\uac8c \\uad6c\\ucd95\\ud574\\uc57c \\ud560\\uae4c\\uc694?\",\n          \"Fat \\ud68c\\uacc4 \\uacfc\\uc815\\uc744 \\ub9c8\\uce5c \\ud6c4\\uc5d0\\ub294 \\uc5b4\\ub5a4 \\uc790\\uaca9\\uc774\\ub098 \\uc778\\uc99d\\uc744 \\ubc1b\\uc744 \\uc218 \\uc788\\uc5b4?\",\n          \"\\uc720\\ub9ac\\uacf5\\uc608 \\uc791\\ud488\\uc744 \\ub9cc\\ub4e4 \\ub54c \\uc608\\uc220\\uac00\\ub4e4\\uc740 \\uc5b4\\ub5a4 \\uc5b4\\ub824\\uc6c0\\uc744 \\uc790\\uc8fc \\uacaa\\uc5b4?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "def load_rm_label_single(path):\n",
        "    # Try utf-8 first, then cp949 to recover Korean in legacy files\n",
        "    data = None\n",
        "    # try:\n",
        "    with open(path, \"r\") as f:\n",
        "        data = json.load(f)\n",
        "        print(len(data))\n",
        "    # except Exception:\n",
        "    #     data = None\n",
        "    # if data is None:\n",
        "    #     raise ValueError(f\"Failed to decode {path}\")\n",
        "\n",
        "    items = data.get(\"data_info\", [])\n",
        "    rows = []\n",
        "    for item in items[:100]:\n",
        "        q = item.get(\"question\", \"\")\n",
        "        if not q:\n",
        "            continue\n",
        "        rows.append({\n",
        "            \"data_id\": item.get(\"data_id\"),\n",
        "            \"question\": q.strip()\n",
        "        })\n",
        "    return rows\n",
        "\n",
        "\n",
        "DATA_ROOT = \"/content/drive/MyDrive/LikeLion/Ïã§Ï†Ñ ÌîÑÎ°úÏ†ùÌä∏ 2/train/RMlabel.json\"\n",
        "\n",
        "rows = load_rm_label_single(DATA_ROOT)\n",
        "print(f\"Loaded {len(rows)} questions\")\n",
        "\n",
        "df = pd.DataFrame(rows).drop_duplicates(subset=[\"data_id\"])\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "26df2b67",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262,
          "referenced_widgets": [
            "fbc20c59e0374e60a122872b2080aa62",
            "8f52b6ccc1b1476d990d09888485213e",
            "314db34e355a4038b76a1838fa72bb28",
            "8975775f32414e9e933d80266331bd3e",
            "8fc12681a05b42dbb598c541d0e49e0c",
            "dcdfa796c3e144ae9d1f4f54d4307c19",
            "6b2e5eb66a4448a99b22145268db1e85",
            "7c192e240fa141f7a4d0f37b96956037",
            "4596b0b888104445a01916756e66d833",
            "07a4b1fe3bb44483b3fe16ae5fd77949",
            "9c0b47d0c6e74d0e98a529bc1a5e952d",
            "038e93a3e65e48b69ef3c388338e5f3a",
            "6884bf8fcacc4c4e92b3d9b75d2ed8f9",
            "051a73e1d1ef4dd5a918b6bf38bcdedf",
            "e5c13dae5812466394075ee14a7a7775",
            "02f23f973f2a4a5699d3279ccef88dd1",
            "2c0aacdf6bca43c3a7f8bdd16f9b8faf",
            "9ce31339ee394d4d826f7a5363d26328",
            "0e3ca4b557834bdbac667067886b928f",
            "537e2ce60b804a32bf0cd8c48b5df829",
            "f94432ce1581485093a02691bb4a65b8",
            "aaebbdf6d4f04d049f7d6f50ccbcd11b",
            "97c3aa0ac61f4609949799e7926ea2cb",
            "00fa0dc7e9dc45278ee7e0027f466efb",
            "8aa38e4744d64f009a2da0237cb461bf",
            "0ec21c5c46884343a3d2e0cd90f7c031",
            "261091f381b64e9fa574026bd6c6c293",
            "dab1989ae1ba4a59a3b6e61bca886a3a",
            "97152522a83d4f57aeba9b975065351c",
            "d9b66477e28d4066bae2411cc24c4b81",
            "cd345ef27420416591331fd5d0948e21",
            "146e02b575844d4dafadf356dac23c40",
            "5bcd3d6ed9c14ec6bc7e45633b538af9"
          ]
        },
        "id": "26df2b67",
        "outputId": "aa897754-80cd-4580-d654-7898ac646696"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì¶ Loading Base model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`torch_dtype` is deprecated! Use `dtype` instead!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fbc20c59e0374e60a122872b2080aa62"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîß Loading RLHF model...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "038e93a3e65e48b69ef3c388338e5f3a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚≠ê Loading Reward model...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "97c3aa0ac61f4609949799e7926ea2cb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at kakaocorp/kanana-1.5-8b-instruct-2505 and are newly initialized: ['score.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ All models loaded!\n"
          ]
        }
      ],
      "source": [
        "def load_causal_model(model_id):\n",
        "    tok = AutoTokenizer.from_pretrained(model_id, use_fast=True, trust_remote_code=True)\n",
        "    if tok.pad_token is None:\n",
        "        tok.pad_token = tok.eos_token\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_id,\n",
        "        torch_dtype=torch.float16,\n",
        "        device_map=\"auto\",\n",
        "        trust_remote_code=True\n",
        "    )\n",
        "    return model, tok\n",
        "\n",
        "# üî• 1. Base Î™®Îç∏ (Ïñ¥ÎåëÌÑ∞ ÏóÜÏùå)\n",
        "print(\"üì¶ Loading Base model...\")\n",
        "base_model, base_tok = load_causal_model(BASE_MODEL_ID)\n",
        "base_model.eval()\n",
        "\n",
        "# üî• 2. RLHF Î™®Îç∏ (Î≥ÑÎèÑ base Ïù∏Ïä§ÌÑ¥Ïä§ + RLHF Ïñ¥ÎåëÌÑ∞)\n",
        "print(\"üîß Loading RLHF model...\")\n",
        "rlhf_base, rlhf_tok = load_causal_model(BASE_MODEL_ID)\n",
        "rlhf_model = PeftModel.from_pretrained(\n",
        "    rlhf_base,\n",
        "    RLHF_ADAPTER_ID,\n",
        "    torch_dtype=torch.float16,\n",
        ")\n",
        "rlhf_model.eval()\n",
        "\n",
        "# üî• 3. Reward Î™®Îç∏ (SequenceClassification + RM Ïñ¥ÎåëÌÑ∞)\n",
        "print(\"‚≠ê Loading Reward model...\")\n",
        "rm_base = AutoModelForSequenceClassification.from_pretrained(\n",
        "    BASE_MODEL_ID,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\",\n",
        "    num_labels=1,  # Î¶¨ÏõåÎìú Ïä§ÏΩîÏñ¥ 1Í∞ú\n",
        "    trust_remote_code=True\n",
        ")\n",
        "rm_model = PeftModel.from_pretrained(\n",
        "    rm_base,\n",
        "    REWARD_ADAPTER_ID,\n",
        "    torch_dtype=torch.float16,\n",
        ")\n",
        "rm_model.eval()\n",
        "rm_tok = base_tok\n",
        "\n",
        "print(\"‚úÖ All models loaded!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "77ac909c",
      "metadata": {
        "id": "77ac909c"
      },
      "outputs": [],
      "source": [
        "def build_prompt(question, tokenizer):\n",
        "    if hasattr(tokenizer, \"apply_chat_template\"):\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": question},\n",
        "        ]\n",
        "        return tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "    return f\"Question:\\n{question}\\n\\nAnswer:\\n\"\n",
        "\n",
        "@torch.inference_mode()\n",
        "def generate_answer(model, tokenizer, question, **gen_kwargs):\n",
        "    prompt = build_prompt(question, tokenizer)\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True).to(model.device)\n",
        "    outputs = model.generate(**inputs, **gen_kwargs)\n",
        "    text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    if text.startswith(prompt):\n",
        "        text = text[len(prompt):]\n",
        "    return text.strip()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "709b3c75",
      "metadata": {
        "id": "709b3c75"
      },
      "outputs": [],
      "source": [
        "def rm_format(question, answer):\n",
        "    return f\"Human: {question}\\nAssistant: {answer}\"\n",
        "\n",
        "@torch.inference_mode()\n",
        "def rm_score(question, answer, model, tokenizer):\n",
        "    text = f\"ÏßàÎ¨∏: {question}\\nÎãµÎ≥Ä: {answer}\"\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
        "    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        out = model(**inputs)\n",
        "\n",
        "    # üî• num_labels=1Ïù¥ÎØÄÎ°ú Ïä§ÏπºÎùº Í∞í\n",
        "    score = out.logits.squeeze().float().item()\n",
        "\n",
        "    return score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "f60f3154",
      "metadata": {
        "id": "f60f3154"
      },
      "outputs": [],
      "source": [
        "GPT_PROMPT = '''You are an evaluator judging which answer better matches human preference.\n",
        "\n",
        "Question:\n",
        "{Q}\n",
        "\n",
        "Answer A:\n",
        "{A}\n",
        "\n",
        "Answer B:\n",
        "{B}\n",
        "\n",
        "Evaluation criteria:\n",
        "- Clear and well-structured explanation\n",
        "- Formal written style\n",
        "- Minimal redundancy\n",
        "- Appropriate professional and safe tone\n",
        "- Directly addresses the question\n",
        "\n",
        "Choose which answer is better overall.\n",
        "Output strictly in the following format:\n",
        "Winner: A\n",
        "Reasons:\n",
        "- Clear and well-structured explanation : A\n",
        "- Formal written style : B\n",
        "- Minimal redundancy : B\n",
        "- Appropriate professional and safe tone : A\n",
        "- Directly addresses the question : A\n",
        "Reason: one short sentence\n",
        "'''\n",
        "\n",
        "def parse_gpt_judge(text):\n",
        "    winner = None\n",
        "    m = re.search(r\"Winner:\\s*([AB])\", text)\n",
        "    if m:\n",
        "        winner = m.group(1)\n",
        "    return winner, text\n",
        "\n",
        "def gpt_judge(question, ans_a, ans_b, client, model=OPENAI_MODEL):\n",
        "    prompt = GPT_PROMPT.format(Q=question, A=ans_a, B=ans_b)\n",
        "    resp = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        temperature=0.0,\n",
        "    )\n",
        "    text = resp.choices[0].message.content\n",
        "    return parse_gpt_judge(text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "928d491e",
      "metadata": {
        "id": "928d491e"
      },
      "outputs": [],
      "source": [
        "KOR_STOPWORDS = set([\n",
        "    \"Ïù¥\", \"Í∑∏\", \"Ï†Ä\", \"Í≤É\", \"Ïàò\", \"Îì±\", \"Î∞è\", \"ÏóêÏÑú\", \"ÏúºÎ°ú\", \"ÏóêÍ≤å\", \"ÏúºÎ°úÏç®\",\n",
        "    \"ÌïòÎã§\", \"ÎêòÎã§\", \"ÏûàÎã§\", \"ÏóÜÎã§\", \"Í∑∏Î¶¨Í≥†\", \"ÌïòÏßÄÎßå\", \"ÎòêÌïú\", \"Í∑∏Îü¨ÎÇò\", \"ÎïåÎ¨∏\", \"ÎïåÎ¨∏Ïóê\", \"Î∞è\", \"ÎåÄÌïú\", \"Í¥ÄÎ†®\"\n",
        "])\n",
        "EN_STOPWORDS = set([\"the\", \"a\", \"an\", \"and\", \"or\", \"but\", \"to\", \"of\", \"in\", \"for\", \"on\", \"with\"])\n",
        "\n",
        "FORMAL_ENDINGS = [\"ÏûÖÎãàÎã§\", \"Ìï©ÎãàÎã§\", \"Îê©ÎãàÎã§\", \"ÌïòÏã≠ÏãúÏò§\", \"ÏäµÎãàÎã§\"]\n",
        "COLLOQUIAL_ENDINGS = [\"Ïöî\", \"Ï£†\", \"Ïùå\"]\n",
        "IMPERATIVE_ENDINGS = [\"ÌïòÏÑ∏Ïöî\", \"ÌïòÏã≠ÏãúÏò§\", \"ÌïòÎùº\", \"ÌïòÏÑ∏Ïöî\"]\n",
        "SPECULATIVE = [\"Ïùº Ïàò\", \"Í∞ÄÎä•\", \"Ï∂îÏ†ï\", \"Î≥¥ÏûÖÎãàÎã§\", \"Í∞ôÏäµÎãàÎã§\"]\n",
        "APOLOGY = [\"Ï£ÑÏÜ°\", \"Ïú†Í∞ê\"]\n",
        "HEDGE = [\"ÏïΩÍ∞Ñ\", \"Ïñ¥Îäê Ï†ïÎèÑ\", \"ÏïÑÎßà\", \"ÎåÄÏ≤¥Î°ú\"]\n",
        "DEFENSIVE = [\"ÎèÑÏõÄÏù¥ ÎêòÍ∏∏ Î∞îÎûçÎãàÎã§\", \"Ï∞∏Í≥† Î∞îÎûçÎãàÎã§\"]\n",
        "ASSERTIVE = [\"Î∞òÎìúÏãú\", \"Ìï≠ÏÉÅ\", \"Ï†àÎåÄ\", \"Î¨¥Ï°∞Í±¥\"]\n",
        "RISKY = [\"ÏûêÏÇ¥\", \"ÏÇ¥Ìï¥\", \"Ìè≠ÌÉÑ\", \"Î∂àÎ≤ï\", \"ÎßàÏïΩ\"]\n",
        "CONDITIONAL = [\"ÎßåÏïΩ\", \"Í≤ΩÏö∞\", \"Îïå\", \"ÎùºÎ©¥\"]\n",
        "NEUTRAL = [\"ÏùºÎ∞òÏ†ÅÏúºÎ°ú\", \"ÎåÄÍ∞ú\", \"Î≥¥ÌÜµ\", \"Ï§ëÎ¶Ω\", \"Í∂åÏû•\"]\n",
        "CONJ = [\"Í∑∏Î¶¨Í≥†\", \"ÌïòÏßÄÎßå\", \"ÎòêÌïú\", \"Í∑∏Îü¨ÎÇò\", \"Ï¶â\", \"Îî∞ÎùºÏÑú\"]\n",
        "SUBORD = [\"ÎïåÎ¨∏Ïóê\", \"Î©¥ÏÑú\", \"ÎèÑÎ°ù\", \"ÎØÄÎ°ú\", \"ÎäîÎç∞\"]\n",
        "\n",
        "def tokenize(text):\n",
        "    # simple mixed tokenizer (Korean/English/digits)\n",
        "    return re.findall(r\"[A-Za-z]+|[0-9]+|[Í∞Ä-Ìû£]+\", text)\n",
        "\n",
        "def split_sentences(text):\n",
        "    parts = re.split(r\"(?<=[\\.\\!\\?])\\s+|\\n+\", text.strip())\n",
        "    return [p.strip() for p in parts if p.strip()]\n",
        "\n",
        "def split_paragraphs(text):\n",
        "    paras = [p.strip() for p in re.split(r\"\\n\\s*\\n\", text) if p.strip()]\n",
        "    return paras if paras else [text.strip()]\n",
        "\n",
        "def ngram_repetition(tokens, n):\n",
        "    if len(tokens) < n:\n",
        "        return 0.0\n",
        "    ngrams = [tuple(tokens[i:i+n]) for i in range(len(tokens)-n+1)]\n",
        "    counts = Counter(ngrams)\n",
        "    repeated = sum(c for c in counts.values() if c > 1)\n",
        "    return repeated / max(1, len(ngrams))\n",
        "\n",
        "def cosine_sim(a, b):\n",
        "    common = set(a) | set(b)\n",
        "    if not common:\n",
        "        return 0.0\n",
        "    va = np.array([a.get(k, 0) for k in common])\n",
        "    vb = np.array([b.get(k, 0) for k in common])\n",
        "    denom = (np.linalg.norm(va) * np.linalg.norm(vb))\n",
        "    if denom == 0:\n",
        "        return 0.0\n",
        "    return float(np.dot(va, vb) / denom)\n",
        "\n",
        "def sentence_similarity_avg(sentences):\n",
        "    if len(sentences) < 2:\n",
        "        return 0.0\n",
        "    vecs = []\n",
        "    for s in sentences:\n",
        "        toks = tokenize(s)\n",
        "        vecs.append(Counter(toks))\n",
        "    sims = []\n",
        "    for i in range(len(vecs)):\n",
        "        for j in range(i+1, len(vecs)):\n",
        "            sims.append(cosine_sim(vecs[i], vecs[j]))\n",
        "    return float(np.mean(sims)) if sims else 0.0\n",
        "\n",
        "def keyword_overuse_ratio(tokens):\n",
        "    if not tokens:\n",
        "        return 0.0\n",
        "    counts = Counter(tokens)\n",
        "    top = sum(c for _, c in counts.most_common(5))\n",
        "    return top / len(tokens)\n",
        "\n",
        "def list_usage_ratio(text):\n",
        "    lines = [l for l in text.splitlines() if l.strip()]\n",
        "    if not lines:\n",
        "        return 0.0\n",
        "    list_lines = sum(1 for l in lines if re.match(r\"\\s*(\\d+\\.|-|\\*)\\s+\", l))\n",
        "    return list_lines / len(lines)\n",
        "\n",
        "def intro_body_conclusion(text):\n",
        "    paras = split_paragraphs(text)\n",
        "    if len(paras) < 2:\n",
        "        return 0\n",
        "    intro = bool(re.search(r\"ÏÑúÎ°†|Í∞úÏöî|Î®ºÏ†Ä\", paras[0]))\n",
        "    concl = bool(re.search(r\"Í≤∞Î°†|ÏöîÏïΩ|ÎßàÎ¨¥Î¶¨\", paras[-1]))\n",
        "    return int(intro and concl)\n",
        "\n",
        "def last_sentence_summary(sentences):\n",
        "    if not sentences:\n",
        "        return 0\n",
        "    return int(bool(re.search(r\"ÏöîÏïΩ|Ï†ïÎ¶¨|Í≤∞Î°†\", sentences[-1])))\n",
        "\n",
        "def ending_ratio(text, endings):\n",
        "    sentences = split_sentences(text)\n",
        "    if not sentences:\n",
        "        return 0.0\n",
        "    hits = 0\n",
        "    for s in sentences:\n",
        "        if any(s.endswith(e) for e in endings):\n",
        "            hits += 1\n",
        "    return hits / len(sentences)\n",
        "\n",
        "def count_ratio(text, patterns):\n",
        "    if not text:\n",
        "        return 0.0\n",
        "    count = sum(text.count(p) for p in patterns)\n",
        "    return count / max(1, len(split_sentences(text)))\n",
        "\n",
        "def comma_density(text):\n",
        "    sentences = split_sentences(text)\n",
        "    if not sentences:\n",
        "        return 0.0\n",
        "    commas = sum(s.count(\",\") for s in sentences)\n",
        "    return commas / len(sentences)\n",
        "\n",
        "def conjunction_density(text):\n",
        "    sentences = split_sentences(text)\n",
        "    if not sentences:\n",
        "        return 0.0\n",
        "    hits = sum(1 for s in sentences if any(c in s for c in CONJ))\n",
        "    return hits / len(sentences)\n",
        "\n",
        "def fragment_ratio(text):\n",
        "    sentences = split_sentences(text)\n",
        "    if not sentences:\n",
        "        return 0.0\n",
        "    endings = FORMAL_ENDINGS + COLLOQUIAL_ENDINGS\n",
        "    fragments = sum(1 for s in sentences if not any(s.endswith(e) for e in endings))\n",
        "    return fragments / len(sentences)\n",
        "\n",
        "def entity_clarity_ratio(text):\n",
        "    sentences = split_sentences(text)\n",
        "    if not sentences:\n",
        "        return 0.0\n",
        "    hits = sum(1 for s in sentences if re.search(r\"(ÏùÄ|Îäî|Ïù¥|Í∞Ä)\", s))\n",
        "    return hits / len(sentences)\n",
        "\n",
        "def keyword_coverage(question, answer):\n",
        "    q_tokens = [t for t in tokenize(question) if t not in KOR_STOPWORDS and t not in EN_STOPWORDS]\n",
        "    if not q_tokens:\n",
        "        return 0.0\n",
        "    a_tokens = set(tokenize(answer))\n",
        "    covered = sum(1 for t in set(q_tokens) if t in a_tokens)\n",
        "    return covered / len(set(q_tokens))\n",
        "\n",
        "def proper_noun_ratio(tokens):\n",
        "    if not tokens:\n",
        "        return 0.0\n",
        "    # heuristic: English capitalized tokens or tokens with digits\n",
        "    hits = sum(1 for t in tokens if re.search(r\"[A-Z]\", t) or re.search(r\"\\d\", t))\n",
        "    return hits / len(tokens)\n",
        "\n",
        "def info_units_per_sentence(text):\n",
        "    sentences = split_sentences(text)\n",
        "    if not sentences:\n",
        "        return 0.0\n",
        "    units = []\n",
        "    for s in sentences:\n",
        "        toks = [t for t in tokenize(s) if t not in KOR_STOPWORDS and t not in EN_STOPWORDS]\n",
        "        units.append(len(set(toks)))\n",
        "    return float(np.mean(units))\n",
        "\n",
        "def stopword_ratio(tokens):\n",
        "    if not tokens:\n",
        "        return 0.0\n",
        "    hits = sum(1 for t in tokens if t in KOR_STOPWORDS or t in EN_STOPWORDS)\n",
        "    return hits / len(tokens)\n",
        "\n",
        "def redundant_sentence_ratio(sentences, threshold=0.8):\n",
        "    if len(sentences) < 2:\n",
        "        return 0.0\n",
        "    vecs = [Counter(tokenize(s)) for s in sentences]\n",
        "    redundant = 0\n",
        "    total = 0\n",
        "    for i in range(len(vecs)):\n",
        "        for j in range(i+1, len(vecs)):\n",
        "            total += 1\n",
        "            if cosine_sim(vecs[i], vecs[j]) >= threshold:\n",
        "                redundant += 1\n",
        "    return redundant / total if total else 0.0\n",
        "\n",
        "def viewpoint_changes(text):\n",
        "    pronouns = [\"Ï†Ä\", \"ÎÇò\", \"Ïö∞Î¶¨\", \"ÎãπÏã†\", \"Í∑∏\", \"Í∑∏ÎÖÄ\", \"Í∑∏Îì§\"]\n",
        "    tokens = tokenize(text)\n",
        "    seq = [t for t in tokens if t in pronouns]\n",
        "    if len(seq) < 2:\n",
        "        return 0\n",
        "    changes = sum(1 for i in range(1, len(seq)) if seq[i] != seq[i-1])\n",
        "    return changes\n",
        "\n",
        "def order_stability(text):\n",
        "    nums = [int(n) for n in re.findall(r\"\\b(\\d+)\\.\", text)]\n",
        "    if len(nums) < 2:\n",
        "        return 1.0\n",
        "    stable = all(nums[i] <= nums[i+1] for i in range(len(nums)-1))\n",
        "    return 1.0 if stable else 0.0\n",
        "\n",
        "def style_features(question, answer):\n",
        "    tokens = tokenize(answer)\n",
        "    sentences = split_sentences(answer)\n",
        "    paras = split_paragraphs(answer)\n",
        "\n",
        "    feats = {}\n",
        "    # 1) length/structure\n",
        "    feats[\"token_count\"] = len(tokens)\n",
        "    feats[\"paragraph_count\"] = len(paras)\n",
        "    feats[\"avg_sentences_per_paragraph\"] = float(np.mean([len(split_sentences(p)) for p in paras])) if paras else 0.0\n",
        "    feats[\"list_usage_ratio\"] = list_usage_ratio(answer)\n",
        "    feats[\"intro_body_conclusion\"] = intro_body_conclusion(answer)\n",
        "    feats[\"first_sentence_length\"] = len(tokenize(sentences[0])) if sentences else 0\n",
        "    feats[\"last_sentence_summary\"] = last_sentence_summary(sentences)\n",
        "\n",
        "    # 2) repetition\n",
        "    feats[\"ngram_rep_2\"] = ngram_repetition(tokens, 2)\n",
        "    feats[\"ngram_rep_3\"] = ngram_repetition(tokens, 3)\n",
        "    feats[\"ngram_rep_4\"] = ngram_repetition(tokens, 4)\n",
        "    feats[\"sentence_similarity_avg\"] = sentence_similarity_avg(sentences)\n",
        "    feats[\"phrase_repeat_rate\"] = answer.count(\"Îã§ÏùåÍ≥º Í∞ôÏäµÎãàÎã§\") / max(1, len(sentences))\n",
        "    feats[\"keyword_overuse_ratio\"] = keyword_overuse_ratio(tokens)\n",
        "\n",
        "    # 3) style/tone\n",
        "    feats[\"formal_ending_ratio\"] = ending_ratio(answer, FORMAL_ENDINGS)\n",
        "    feats[\"colloquial_ratio\"] = ending_ratio(answer, COLLOQUIAL_ENDINGS)\n",
        "    feats[\"exclaim_ratio\"] = answer.count(\"!\") / max(1, len(sentences))\n",
        "    feats[\"question_mark_ratio\"] = answer.count(\"?\") / max(1, len(sentences))\n",
        "    feats[\"first_person_ratio\"] = count_ratio(answer, [\"Ï†ÄÎäî\", \"Ï†úÍ∞Ä\", \"ÎÇòÎäî\", \"Ïö∞Î¶¨\"])\n",
        "    feats[\"imperative_ratio\"] = count_ratio(answer, IMPERATIVE_ENDINGS)\n",
        "    feats[\"speculative_ratio\"] = count_ratio(answer, SPECULATIVE)\n",
        "\n",
        "    # 4) apology/hedge/defensive\n",
        "    feats[\"apology_ratio\"] = count_ratio(answer, APOLOGY)\n",
        "    feats[\"defensive_ratio\"] = count_ratio(answer, DEFENSIVE)\n",
        "    feats[\"hedge_ratio\"] = count_ratio(answer, HEDGE)\n",
        "\n",
        "    # 5) clarity\n",
        "    feats[\"avg_sentence_length\"] = float(np.mean([len(tokenize(s)) for s in sentences])) if sentences else 0.0\n",
        "    feats[\"subordinate_ratio\"] = count_ratio(answer, SUBORD)\n",
        "    feats[\"comma_density\"] = comma_density(answer)\n",
        "    feats[\"conjunction_density\"] = conjunction_density(answer)\n",
        "    feats[\"fragment_ratio\"] = fragment_ratio(answer)\n",
        "    feats[\"entity_clarity_ratio\"] = entity_clarity_ratio(answer)\n",
        "\n",
        "    # 6) info density\n",
        "    feats[\"proper_noun_ratio\"] = proper_noun_ratio(tokens)\n",
        "    feats[\"keyword_coverage\"] = keyword_coverage(question, answer)\n",
        "    feats[\"info_units_per_sentence\"] = info_units_per_sentence(answer)\n",
        "    feats[\"stopword_ratio\"] = stopword_ratio(tokens)\n",
        "    feats[\"redundant_sentence_ratio\"] = redundant_sentence_ratio(sentences)\n",
        "\n",
        "    # 7) safety/neutral\n",
        "    feats[\"assertive_ratio\"] = count_ratio(answer, ASSERTIVE)\n",
        "    feats[\"risky_keyword_ratio\"] = count_ratio(answer, RISKY)\n",
        "    feats[\"conditional_ratio\"] = count_ratio(answer, CONDITIONAL)\n",
        "    feats[\"neutral_vocab_ratio\"] = count_ratio(answer, NEUTRAL)\n",
        "\n",
        "    # 8) consistency\n",
        "    feats[\"question_keyword_reuse\"] = keyword_coverage(question, answer)\n",
        "    feats[\"viewpoint_changes\"] = viewpoint_changes(answer)\n",
        "    feats[\"logic_connector_consistency\"] = conjunction_density(answer)\n",
        "    feats[\"order_stability\"] = order_stability(answer)\n",
        "\n",
        "    return feats\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "390b84a5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "390b84a5",
        "outputId": "10bba5cc-8e56-4ee7-8486-555d1267106c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [1:28:08<00:00, 52.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/LikeLion/Ïã§Ï†Ñ ÌîÑÎ°úÏ†ùÌä∏ 2/evaluation/artifacts_20260121_161654/generations/base_generations_20260121_161654.jsonl\n",
            "/content/drive/MyDrive/LikeLion/Ïã§Ï†Ñ ÌîÑÎ°úÏ†ùÌä∏ 2/evaluation/artifacts_20260121_161654/generations/rlhf_generations_20260121_161654.jsonl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Stage 1: generate and save JSONL per model\n",
        "base_out = os.path.join(GEN_DIR, f\"base_generations_{TIMESTAMP}.jsonl\")\n",
        "rlhf_out = os.path.join(GEN_DIR, f\"rlhf_generations_{TIMESTAMP}.jsonl\")\n",
        "\n",
        "def write_jsonl(path, rows):\n",
        "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
        "        for r in rows:\n",
        "            f.write(json.dumps(r, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "base_rows = []\n",
        "rlhf_rows = []\n",
        "for _, row in tqdm(df.iterrows(), total=len(df)):\n",
        "    q = row[\"question\"]\n",
        "    data_id = row[\"data_id\"]\n",
        "    base_ans = generate_answer(base_model, base_tok, q, **GEN_KWARGS)\n",
        "    rlhf_ans = generate_answer(rlhf_model, rlhf_tok, q, **GEN_KWARGS)\n",
        "\n",
        "    base_rows.append({\"data_id\": data_id, \"question\": q, ANSWER_KEY: base_ans})\n",
        "    rlhf_rows.append({\"data_id\": data_id, \"question\": q, ANSWER_KEY: rlhf_ans})\n",
        "\n",
        "write_jsonl(base_out, base_rows)\n",
        "write_jsonl(rlhf_out, rlhf_rows)\n",
        "print(base_out)\n",
        "print(rlhf_out)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "75c711ee",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75c711ee",
        "outputId": "294b6b7c-6800-4146-e0e1-b7b58cc7c97d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [04:21<00:00,  2.61s/it]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# Stage 2: evaluate from saved JSONL\n",
        "from google.colab import userdata\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "base_out = os.path.join(GEN_DIR, f\"base_generations_{TIMESTAMP}.jsonl\")\n",
        "rlhf_out = os.path.join(GEN_DIR, f\"rlhf_generations_{TIMESTAMP}.jsonl\")\n",
        "\n",
        "# load_dotenv()\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")\n",
        "\n",
        "def read_jsonl(path):\n",
        "    rows = []\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            if line.strip():\n",
        "                rows.append(json.loads(line))\n",
        "    return rows\n",
        "\n",
        "base_rows = read_jsonl(base_out)\n",
        "rlhf_rows = read_jsonl(rlhf_out)\n",
        "base_map = {r[\"data_id\"]: r for r in base_rows}\n",
        "rlhf_map = {r[\"data_id\"]: r for r in rlhf_rows}\n",
        "\n",
        "results = []\n",
        "if RUN_GPT_EVAL:\n",
        "    from openai import OpenAI\n",
        "    client = OpenAI()\n",
        "else:\n",
        "    client = None\n",
        "\n",
        "for data_id in tqdm(sorted(set(base_map) & set(rlhf_map))):\n",
        "    q = base_map[data_id][\"question\"]\n",
        "    base_ans = base_map[data_id][ANSWER_KEY]\n",
        "    rlhf_ans = rlhf_map[data_id][ANSWER_KEY]\n",
        "\n",
        "    base_rm = rm_score(q, base_ans, rm_model, rm_tok)\n",
        "    rlhf_rm = rm_score(q, rlhf_ans, rm_model, rm_tok)\n",
        "\n",
        "    gpt_winner = None\n",
        "    gpt_raw = None\n",
        "    if RUN_GPT_EVAL:\n",
        "        gpt_winner, gpt_raw = gpt_judge(q, rlhf_ans, base_ans, client)\n",
        "\n",
        "    base_feats = style_features(q, base_ans)\n",
        "    rlhf_feats = style_features(q, rlhf_ans)\n",
        "\n",
        "    results.append({\n",
        "        \"data_id\": data_id,\n",
        "        \"question\": q,\n",
        "        \"base_answer\": base_ans,\n",
        "        \"rlhf_answer\": rlhf_ans,\n",
        "        \"base_rm_score\": base_rm,\n",
        "        \"rlhf_rm_score\": rlhf_rm,\n",
        "        \"gpt_winner\": gpt_winner,\n",
        "        \"gpt_raw\": gpt_raw,\n",
        "        \"base_features\": base_feats,\n",
        "        \"rlhf_features\": rlhf_feats,\n",
        "    })\n",
        "\n",
        "len(results)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "a53aaeb3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "a53aaeb3",
        "outputId": "b5a50d31-9303-42ee-fe51-c06b7b74377e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       rm_score           token_count            paragraph_count            \\\n",
              "           mean       std        mean        std            mean       std   \n",
              "model                                                                        \n",
              "base  -0.992939  3.295954      198.41  36.062823           12.04  2.813819   \n",
              "rlhf  -1.057489  3.303440      201.15  31.457322           12.14  2.593777   \n",
              "\n",
              "      avg_sentences_per_paragraph           list_usage_ratio            ...  \\\n",
              "                             mean       std             mean       std  ...   \n",
              "model                                                                   ...   \n",
              "base                     2.581599  0.619671         0.524617  0.197954  ...   \n",
              "rlhf                     2.577811  0.413872         0.536161  0.152850  ...   \n",
              "\n",
              "      neutral_vocab_ratio           question_keyword_reuse       \\\n",
              "                     mean       std                   mean  std   \n",
              "model                                                             \n",
              "base             0.008062  0.020033                    1.0  0.0   \n",
              "rlhf             0.011200  0.026935                    1.0  0.0   \n",
              "\n",
              "      viewpoint_changes           logic_connector_consistency            \\\n",
              "                   mean       std                        mean       std   \n",
              "model                                                                     \n",
              "base               0.01  0.100000                    0.015942  0.032406   \n",
              "rlhf               0.02  0.140705                    0.013434  0.024465   \n",
              "\n",
              "      order_stability            \n",
              "                 mean       std  \n",
              "model                            \n",
              "base             0.89  0.314466  \n",
              "rlhf             0.92  0.272660  \n",
              "\n",
              "[2 rows x 86 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bb818651-c4db-4721-9b0f-1c17fea6d5b4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th colspan=\"2\" halign=\"left\">rm_score</th>\n",
              "      <th colspan=\"2\" halign=\"left\">token_count</th>\n",
              "      <th colspan=\"2\" halign=\"left\">paragraph_count</th>\n",
              "      <th colspan=\"2\" halign=\"left\">avg_sentences_per_paragraph</th>\n",
              "      <th colspan=\"2\" halign=\"left\">list_usage_ratio</th>\n",
              "      <th>...</th>\n",
              "      <th colspan=\"2\" halign=\"left\">neutral_vocab_ratio</th>\n",
              "      <th colspan=\"2\" halign=\"left\">question_keyword_reuse</th>\n",
              "      <th colspan=\"2\" halign=\"left\">viewpoint_changes</th>\n",
              "      <th colspan=\"2\" halign=\"left\">logic_connector_consistency</th>\n",
              "      <th colspan=\"2\" halign=\"left\">order_stability</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>...</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>model</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>base</th>\n",
              "      <td>-0.992939</td>\n",
              "      <td>3.295954</td>\n",
              "      <td>198.41</td>\n",
              "      <td>36.062823</td>\n",
              "      <td>12.04</td>\n",
              "      <td>2.813819</td>\n",
              "      <td>2.581599</td>\n",
              "      <td>0.619671</td>\n",
              "      <td>0.524617</td>\n",
              "      <td>0.197954</td>\n",
              "      <td>...</td>\n",
              "      <td>0.008062</td>\n",
              "      <td>0.020033</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.015942</td>\n",
              "      <td>0.032406</td>\n",
              "      <td>0.89</td>\n",
              "      <td>0.314466</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rlhf</th>\n",
              "      <td>-1.057489</td>\n",
              "      <td>3.303440</td>\n",
              "      <td>201.15</td>\n",
              "      <td>31.457322</td>\n",
              "      <td>12.14</td>\n",
              "      <td>2.593777</td>\n",
              "      <td>2.577811</td>\n",
              "      <td>0.413872</td>\n",
              "      <td>0.536161</td>\n",
              "      <td>0.152850</td>\n",
              "      <td>...</td>\n",
              "      <td>0.011200</td>\n",
              "      <td>0.026935</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.140705</td>\n",
              "      <td>0.013434</td>\n",
              "      <td>0.024465</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0.272660</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows √ó 86 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bb818651-c4db-4721-9b0f-1c17fea6d5b4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bb818651-c4db-4721-9b0f-1c17fea6d5b4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bb818651-c4db-4721-9b0f-1c17fea6d5b4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "summary"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# Flatten results for analysis\n",
        "rows = []\n",
        "for r in results:\n",
        "    base = {\"model\": \"base\", \"data_id\": r[\"data_id\"], \"rm_score\": r[\"base_rm_score\"], **r[\"base_features\"]}\n",
        "    rlhf = {\"model\": \"rlhf\", \"data_id\": r[\"data_id\"], \"rm_score\": r[\"rlhf_rm_score\"], **r[\"rlhf_features\"]}\n",
        "    rows.extend([base, rlhf])\n",
        "\n",
        "feat_df = pd.DataFrame(rows)\n",
        "feat_df.to_csv(os.path.join(EVAL_DIR, f\"style_metrics_{TIMESTAMP}.csv\"), index=False)\n",
        "\n",
        "raw_path = os.path.join(EVAL_DIR, f\"raw_results_{TIMESTAMP}.json\")\n",
        "with open(raw_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(results, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "# GPT win rate\n",
        "gpt_wins = [r[\"gpt_winner\"] for r in results if r[\"gpt_winner\"]]\n",
        "gpt_win_rate = None\n",
        "if gpt_wins:\n",
        "    gpt_win_rate = gpt_wins.count(\"A\") / len(gpt_wins)\n",
        "\n",
        "numeric_df = feat_df.select_dtypes(include=\"number\")\n",
        "\n",
        "summary = (\n",
        "    pd.concat([feat_df[\"model\"], numeric_df], axis=1)\n",
        "      .groupby(\"model\")\n",
        "      .agg([\"mean\", \"std\"])\n",
        ")\n",
        "summary.to_csv(os.path.join(EVAL_DIR, f\"style_metrics_summary_{TIMESTAMP}.csv\"))\n",
        "summary.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "b3925d8b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "b3925d8b",
        "outputId": "06731c62-8eee-4273-b017-1807889a9940"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/LikeLion/Ïã§Ï†Ñ ÌîÑÎ°úÏ†ùÌä∏ 2/evaluation/rlhf_eval_report_20260121_161654.md'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "def write_report(path, feat_df, gpt_win_rate, dataset_paths):\n",
        "    models = feat_df[\"model\"].unique().tolist()\n",
        "    metrics = [c for c in feat_df.columns if c not in [\"model\", \"data_id\"]]\n",
        "\n",
        "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(\"# RLHF Evaluation Report\\n\\n\")\n",
        "        f.write(\"## Dataset\\n\")\n",
        "        f.write(f\"- Source files: {len(dataset_paths)}\\n\")\n",
        "        f.write(f\"- Samples used: {feat_df['data_id'].nunique()}\\n\\n\")\n",
        "\n",
        "        f.write(\"## RM Score\\n\")\n",
        "        for m in models:\n",
        "            mean = feat_df[feat_df[\"model\"] == m][\"rm_score\"].mean()\n",
        "            std = feat_df[feat_df[\"model\"] == m][\"rm_score\"].std()\n",
        "            f.write(f\"- {m}: mean={mean:.4f}, std={std:.4f}\\n\")\n",
        "        f.write(\"\\n\")\n",
        "\n",
        "        f.write(\"## GPT Preference (A=RLHF, B=Base)\\n\")\n",
        "        if gpt_win_rate is None:\n",
        "            f.write(\"- GPT eval not run.\\n\")\n",
        "        else:\n",
        "            f.write(f\"- RLHF win rate: {gpt_win_rate:.3f}\\n\")\n",
        "        f.write(\"\\n\")\n",
        "\n",
        "        f.write(\"## Style Metrics (mean ¬± std)\\n\")\n",
        "        for metric in metrics:\n",
        "            if metric == \"rm_score\":\n",
        "                continue\n",
        "            f.write(f\"### {metric}\\n\")\n",
        "            for m in models:\n",
        "                s = feat_df[feat_df[\"model\"] == m][metric]\n",
        "                f.write(f\"- {m}: {s.mean():.4f} ¬± {s.std():.4f}\\n\")\n",
        "            f.write(\"\\n\")\n",
        "\n",
        "        f.write(\"## Notes\\n\")\n",
        "        f.write(\"- Style metrics use lightweight heuristics. Replace with a richer tokenizer or domain-specific analyzer if needed.\\n\")\n",
        "\n",
        "write_report(REPORT_PATH, feat_df, gpt_win_rate, DATA_ROOT)\n",
        "REPORT_PATH\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# RM Model Huggingface PushÏö© ÏûÑÏãú ÏΩîÎìú\n",
        "import os\n",
        "from huggingface_hub import create_repo, upload_folder\n",
        "from google.colab import drive, userdata\n",
        "\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "RM_ADAPTER_DIR = \"/content/drive/MyDrive/LikeLion/Ïã§Ï†Ñ ÌîÑÎ°úÏ†ùÌä∏ 2/train/kanana-1.5-8b-rm-checkpoint(new)\"\n",
        "os.environ[\"HF_TOKEN\"] = userdata.get(\"HF_TOKEN\")\n",
        "\n",
        "create_repo(\n",
        "    repo_id=\"jinn33/kanana-1.5-8b-rm\",\n",
        "    repo_type=\"model\",\n",
        "    private=False,\n",
        "    exist_ok=True,\n",
        ")\n",
        "\n",
        "upload_folder(\n",
        "    repo_id=\"jinn333/kanana-1.5-8b-rm\",\n",
        "    repo_type=\"model\",\n",
        "    folder_path=RM_ADAPTER_DIR,\n",
        ")"
      ],
      "metadata": {
        "id": "qj6TX-efLrCa"
      },
      "id": "qj6TX-efLrCa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RM Î™®Îç∏ shape ÌôïÏù∏\n",
        "def check_rm_shape(model, tokenizer):\n",
        "    # ÌÖåÏä§Ìä∏ ÏûÖÎ†•\n",
        "    test_q = \"ÏïàÎÖïÌïòÏÑ∏Ïöî?\"\n",
        "    test_a = \"ÎÑ§, ÏïàÎÖïÌïòÏÑ∏Ïöî! Î¨¥ÏóáÏùÑ ÎèÑÏôÄÎìúÎ¶¥ÍπåÏöî?\"\n",
        "\n",
        "    text = rm_format(test_q, test_a)\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True).to(model.device)\n",
        "\n",
        "    print(\"=== Input Info ===\")\n",
        "    print(f\"Input text length: {len(text)}\")\n",
        "    print(f\"Input IDs shape: {inputs['input_ids'].shape}\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        out = model(**inputs)\n",
        "\n",
        "    print(\"\\n=== Output Info ===\")\n",
        "    print(f\"Output type: {type(out)}\")\n",
        "    print(f\"Output attributes: {dir(out)}\")\n",
        "    print(f\"Logits shape: {out.logits.shape}\")\n",
        "    print(f\"Logits dtype: {out.logits.dtype}\")\n",
        "    print(f\"\\nFirst few logits values:\")\n",
        "    print(out.logits[0, :5, :])  # Ï≤òÏùå 5Í∞ú ÌÜ†ÌÅ∞\n",
        "    print(f\"\\nLast few logits values:\")\n",
        "    print(out.logits[0, -5:, :])  # ÎßàÏßÄÎßâ 5Í∞ú ÌÜ†ÌÅ∞\n",
        "\n",
        "    print(\"\\n=== After Squeeze ===\")\n",
        "    squeezed = out.logits.squeeze()\n",
        "    print(f\"Squeezed shape: {squeezed.shape}\")\n",
        "    print(f\"Squeezed dim: {squeezed.dim()}\")\n",
        "\n",
        "# Ïã§Ìñâ\n",
        "check_rm_shape(rm_model, rm_tok)"
      ],
      "metadata": {
        "id": "S5Pxe0UqwWjY"
      },
      "id": "S5Pxe0UqwWjY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rm_model"
      ],
      "metadata": {
        "id": "cEtn1SN0QIuM",
        "outputId": "6659d2ca-9718-4761-8ae7-16c97e519742",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "cEtn1SN0QIuM",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PeftModelForSequenceClassification(\n",
              "  (base_model): LoraModel(\n",
              "    (model): LlamaForSequenceClassification(\n",
              "      (model): LlamaModel(\n",
              "        (embed_tokens): Embedding(128259, 4096, padding_idx=128001)\n",
              "        (layers): ModuleList(\n",
              "          (0-31): 32 x LlamaDecoderLayer(\n",
              "            (self_attn): LlamaAttention(\n",
              "              (q_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=64, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=64, out_features=4096, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
              "              (v_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=4096, out_features=1024, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=64, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=64, out_features=1024, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "            )\n",
              "            (mlp): LlamaMLP(\n",
              "              (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
              "              (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
              "              (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
              "              (act_fn): SiLUActivation()\n",
              "            )\n",
              "            (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
              "            (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
              "          )\n",
              "        )\n",
              "        (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
              "        (rotary_emb): LlamaRotaryEmbedding()\n",
              "      )\n",
              "      (score): ModulesToSaveWrapper(\n",
              "        (original_module): Linear(in_features=4096, out_features=1, bias=False)\n",
              "        (modules_to_save): ModuleDict(\n",
              "          (default): Linear(in_features=4096, out_features=1, bias=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "fbc20c59e0374e60a122872b2080aa62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8f52b6ccc1b1476d990d09888485213e",
              "IPY_MODEL_314db34e355a4038b76a1838fa72bb28",
              "IPY_MODEL_8975775f32414e9e933d80266331bd3e"
            ],
            "layout": "IPY_MODEL_8fc12681a05b42dbb598c541d0e49e0c"
          }
        },
        "8f52b6ccc1b1476d990d09888485213e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dcdfa796c3e144ae9d1f4f54d4307c19",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_6b2e5eb66a4448a99b22145268db1e85",
            "value": "Loading‚Äácheckpoint‚Äáshards:‚Äá100%"
          }
        },
        "314db34e355a4038b76a1838fa72bb28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c192e240fa141f7a4d0f37b96956037",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4596b0b888104445a01916756e66d833",
            "value": 4
          }
        },
        "8975775f32414e9e933d80266331bd3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07a4b1fe3bb44483b3fe16ae5fd77949",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_9c0b47d0c6e74d0e98a529bc1a5e952d",
            "value": "‚Äá4/4‚Äá[00:04&lt;00:00,‚Äá‚Äá1.07s/it]"
          }
        },
        "8fc12681a05b42dbb598c541d0e49e0c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dcdfa796c3e144ae9d1f4f54d4307c19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b2e5eb66a4448a99b22145268db1e85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7c192e240fa141f7a4d0f37b96956037": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4596b0b888104445a01916756e66d833": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "07a4b1fe3bb44483b3fe16ae5fd77949": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c0b47d0c6e74d0e98a529bc1a5e952d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "038e93a3e65e48b69ef3c388338e5f3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6884bf8fcacc4c4e92b3d9b75d2ed8f9",
              "IPY_MODEL_051a73e1d1ef4dd5a918b6bf38bcdedf",
              "IPY_MODEL_e5c13dae5812466394075ee14a7a7775"
            ],
            "layout": "IPY_MODEL_02f23f973f2a4a5699d3279ccef88dd1"
          }
        },
        "6884bf8fcacc4c4e92b3d9b75d2ed8f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c0aacdf6bca43c3a7f8bdd16f9b8faf",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_9ce31339ee394d4d826f7a5363d26328",
            "value": "Loading‚Äácheckpoint‚Äáshards:‚Äá100%"
          }
        },
        "051a73e1d1ef4dd5a918b6bf38bcdedf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e3ca4b557834bdbac667067886b928f",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_537e2ce60b804a32bf0cd8c48b5df829",
            "value": 4
          }
        },
        "e5c13dae5812466394075ee14a7a7775": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f94432ce1581485093a02691bb4a65b8",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_aaebbdf6d4f04d049f7d6f50ccbcd11b",
            "value": "‚Äá4/4‚Äá[00:04&lt;00:00,‚Äá‚Äá1.04s/it]"
          }
        },
        "02f23f973f2a4a5699d3279ccef88dd1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c0aacdf6bca43c3a7f8bdd16f9b8faf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ce31339ee394d4d826f7a5363d26328": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0e3ca4b557834bdbac667067886b928f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "537e2ce60b804a32bf0cd8c48b5df829": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f94432ce1581485093a02691bb4a65b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aaebbdf6d4f04d049f7d6f50ccbcd11b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "97c3aa0ac61f4609949799e7926ea2cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_00fa0dc7e9dc45278ee7e0027f466efb",
              "IPY_MODEL_8aa38e4744d64f009a2da0237cb461bf",
              "IPY_MODEL_0ec21c5c46884343a3d2e0cd90f7c031"
            ],
            "layout": "IPY_MODEL_261091f381b64e9fa574026bd6c6c293"
          }
        },
        "00fa0dc7e9dc45278ee7e0027f466efb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dab1989ae1ba4a59a3b6e61bca886a3a",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_97152522a83d4f57aeba9b975065351c",
            "value": "Loading‚Äácheckpoint‚Äáshards:‚Äá100%"
          }
        },
        "8aa38e4744d64f009a2da0237cb461bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9b66477e28d4066bae2411cc24c4b81",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cd345ef27420416591331fd5d0948e21",
            "value": 4
          }
        },
        "0ec21c5c46884343a3d2e0cd90f7c031": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_146e02b575844d4dafadf356dac23c40",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_5bcd3d6ed9c14ec6bc7e45633b538af9",
            "value": "‚Äá4/4‚Äá[00:04&lt;00:00,‚Äá‚Äá1.05it/s]"
          }
        },
        "261091f381b64e9fa574026bd6c6c293": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dab1989ae1ba4a59a3b6e61bca886a3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97152522a83d4f57aeba9b975065351c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d9b66477e28d4066bae2411cc24c4b81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd345ef27420416591331fd5d0948e21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "146e02b575844d4dafadf356dac23c40": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5bcd3d6ed9c14ec6bc7e45633b538af9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}