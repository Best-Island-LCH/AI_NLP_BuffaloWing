# 📊 [Report] LLM 베이스라인 모델 성능 비교 분석 (2차)

## 1. 실험 개요 (Experiment Overview)
• **목적**: NIA097 한국어 SFT 데이터셋에 최적화된 QA 봇 개발을 위한 최적의 오픈소스 베이스라인 모델 선정.
• **일시**: 2026년 1월 18일.  
• **대상 모델**: 
`SOLAR`, `QWEN`, `Llama-3`, `KOGPT2`, `POLYGLOT`

• **하드웨어 환경**
**GPU**: NVIDIA A100 Tensor Core GPU (VRAM 40GB)

**System RAM**: 83.5 GB

**Compute Unit**: Colab Pro+ 환경

## 2. 실험 결과 요약(Quantitative Results)   
| **모델명** | **체급(Params)** | **ROUGH-L** | **추론 속도(10회)** | **최종 상태** |
| --- | --- | --- | --- | --- |
| **SOLAR** | 10.7B | 0.0696 | 50초 | 우수 |
| **QWEN** | 7B | 0.0432 | 42초 | 보통 |
| **LLAMA3** | 8B | 0.0000 | 47초 | 보통 |
| **KOGPT2** | 125M | 0.0000 | 14초 | 부적격 |
| **POLYGLOT** | 1.3B | -- | -- | 에러 (중단) |

**실험 결과 분석**: SOLAR-10.7B 모델이 가장 높은 ROUGE-L 점수를 기록하며 한국어 지시 이행 능력에서 우위를 점했습니다. 반면, Polyglot은 기술적 결함으로 인해 실험이 중단되었습니다.

## 3. 모델별 상세 분석 (Qualitative Analysis)
### 3.1 Upstage SOLAR-10.7B (성능 최상)
강점: 한국어 문맥 이해도가 가장 뛰어나며, 질문에 대한 답변 키워드 생성 능력이 안정적임.

약점: 10.7B의 큰 체급으로 인해 A100 환경에서도 일부 CPU Offloading이 발생하여 추론 지연(50초)이 관측됨.

특이사항: 간헐적인 인코딩 깨짐 현상과 사전 학습된 외부 지식(예: 타국 헌법)을 인출하는 환각 현상이 일부 나타남.

### 3.2 Qwen-7B (가성비 및 균형)
강점: 추론 속도(42초)와 성능(0.0432) 사이의 균형이 좋으며, 한국어 구조를 일정 수준 파악함.

약점: 전문적인 QA 데이터(NIA097)의 고도화된 문장을 완벽히 복제하는 데는 한계를 보임.

### 3.3 Meta Llama-3-8B & KoGPT2 (언어 및 체급 한계)
Llama-3: 글로벌 성능은 탁월하나, 제로샷 한국어 답변 시 영문으로 응답하거나 한국어 문화를 수필 형식으로 해석하는 '언어 미스매치' 발생.

KoGPT2: 추론 속도는 가장 빠르나(14초), 파라미터 수의 부족으로 인해 복잡한 지시 사항을 이행하지 못하고 점수 산출이 불가함.

### 3.4 EleutherAI Polyglot-1.3B (기술적 오류)
에러 원인: model.generate 함수 실행 시, 토크나이저에서 생성된 token_type_ids 인자가 모델에 전달되면서 'Unused kwargs' 에러 발생.

교훈: 향후 다양한 아키텍처를 테스트할 때 인자 값을 유연하게 처리하는 전처리 파이프라인의 필요성을 시사함.

## 4. 결론(Conclusion)
**SFT 데이터 학습의 필요성**: 베이스라인 모델들의 점수가 0.1 미만으로 집계된 것은 전문 데이터셋(NIA097)의 난이도가 높음을 의미하며, 단순 추론보다는 **지도 미세 조정(SFT)**을 통한 형식이 고정이 필수적임.

**리소스 관리 전략**: A100 40GB 환경을 온전히 활용하기 위해, SOLAR와 같은 대형 모델은 4비트 양자화 또는 효율적인 메모리 할당(device_map) 설정이 수반되어야 함.
