# π“ [Report] LLM λ² μ΄μ¤λΌμΈ λ¨λΈ μ„±λ¥ λΉ„κµ λ¶„μ„ (1μ°¨)

## 1. μ‹¤ν— κ°μ” (Experiment Overview)
β€Ά **λ©μ **: NIA097 ν•κµ­μ–΄ SFT λ°μ΄ν„°μ…‹μ— μµμ ν™”λ QA λ΄‡ κ°λ°μ„ μ„ν• μµμ μ μ¤ν”μ†μ¤ λ² μ΄μ¤λΌμΈ λ¨λΈ μ„ μ •.
β€Ά **μΌμ‹**: 2026λ…„ 1μ›” 18μΌ.  
β€Ά **λ€μƒ λ¨λΈ**: 
`Upstage SOLAR-10.7B`, `Meta Llama-3-8B`

β€Ά **ν•λ“μ›¨μ–΄ ν™κ²½**
**GPU**: NVIDIA A100 Tensor Core GPU (VRAM 40GB)

**System RAM**: 83.5 GB

**Compute Unit**: Colab Pro+ ν™κ²½

## 2. λ°μ΄ν„° νμ΄ν”„λΌμΈ (Data Pipeline)   
β€Ά **λ°μ΄ν„° λ³‘ν•©**: data_idλ¥Ό κ³ μ  μ‹λ³„μλ΅ ν™μ©ν•μ—¬ SFTdata.json(μ§λ¬Έ)κ³Ό SFTlabel.json(λ¨λ²” λ‹µμ•)μ„ 1:1 λ§¤ν•‘

β€Ά **λ°μ΄ν„° κ·λ¨**: μ΄ 10,580κ°μ μ ν¨ λ°μ΄ν„° μ„ΈνΈ μ •μ  μ™„λ£

β€Ά **ν‰κ°€ λ°©λ²•**: μ „μ²΄ λ°μ΄ν„°μ…‹ μ¤‘ 10κ°λ¥Ό λ¬΄μ‘μ„ μƒν”λ§ν•μ—¬ μ λ΅μƒ·(Zero-shot) μ¶”λ΅  μν–‰

## 3. μ •λ‰μ  ν‰κ°€ (Quantitative Evaluation)
### [3.1 μ¶”λ΅  ν¨μ¨μ„± λ° μμ› μ μ ]

| **ν•­λ©** | **Upstage SOLAR-10.7B** | **Meta Llama-3-8B** |
| --- | --- | --- |
| **μ¶”λ΅  μ†μ” μ‹κ°„** | **5,663μ΄ (μ•½ 94.3λ¶„)** | **540μ΄ (9.0λ¶„)** |
| **μμ› ν¨μ¨μ„±** | CPU Offloading λ°μƒ (μ§€μ—° ν•µμ‹¬ μ›μΈ) | μμ GPU κ°€μ† μ—°μ‚° (μµμ ν™” μ™„λ£) |
| **ROUGH-1** | 0.1253 | 0.0034 |
| **ROUGH-L** | 0.1031 | 0.0034 |

## 4. μ •μ„±μ  ν‰κ°€
### β SOLAR-10.7B: μ§€μ‹ ννΈν™” λ° ν™κ° (Hallucination)
**μΈμ½”λ”© μ΄μ**: ν•κµ­μ–΄ ν† ν° μƒμ„± κ³Όμ •μ—μ„ ``μ™€ κ°™μ€ κΉ¨μ§ ν„μƒμ΄ λΉλ²ν•κ² λ°μƒν•μ—¬ κ°€λ…μ„±μ„ μ €ν•΄ν•¨.

**λ„λ©”μΈ μ΄νƒ**: μ§λ¬Έμ λ§¥λ½μ„ μ΄νƒν•μ—¬ 'λΌμ΄λ² λ¦¬μ•„ ν—λ²•' λ“± μ‚¬μ „ ν•™μµλ λ¬΄κ΄€ν• μ§€μ‹μ„ λ¬΄μ‘μ„λ΅ μΈμ¶ν•¨.

**κΈμ •μ  μ”μ†**: ν•κµ­μ–΄ μ§λ¬Έμ— λ€ν•΄ ν•κµ­μ–΄ ν‚¤μ›λ“λ΅ μ‘λ‹µν•λ ¤λ” μ‹λ„κ°€ κ΄€μΈ΅λμ–΄, μ–Έμ–΄ μ ν•©μ„± μΈ΅λ©΄μ—μ„λ” κ°€λ¥μ„±μ„ λ³΄μ„.

### β LLAMA3-8B: μ–Έμ–΄ λ―Έμ¤λ§¤μΉ (Language Mismatch)
**μμ–΄ νΈν–¥μ„±**: ν•κµ­μ–΄ μ§€μ‹(Prompt)λ¥Ό μ΄ν•΄ν–μμ—λ„ λ‹µλ³€μ„ μμ–΄λ΅ μƒμ„±ν•κ±°λ‚, μ§λ¬Έ μμ²΄λ¥Ό μμ–΄λ΅ λ²μ—­ν•μ—¬ μ¬μ§λ¬Έν•λ” μ–‘μƒμ„ λ³΄μ„.

**λ¬Έν™”μ  μ΄ν•΄λ„ λ¶€μ¬**: 'μ†λ†'κ³Ό κ°™μ€ ν•κµ­μ–΄ νΉμ μ μ‚¬νΒ·λ¬Έν™”μ  λ§¥λ½μ΄ ν¬ν•¨λ μ§λ¬Έμ— λ€ν•΄ μν•„ ν•μ‹μ λ¬΄κ΄€ν• λ‹µλ³€μ„ μƒμ„±ν•¨.